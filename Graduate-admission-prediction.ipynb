{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f01f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('DEEP LEARNING'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58624eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e68a15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9827e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf998baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a3afef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecde5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1521d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf6cb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2041780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd39f22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6176248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0e5bf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>301</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>305</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>318</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "93         301           97                  2  3.0   3.0  7.88         1\n",
       "23         334          119                  5  5.0   4.5  9.70         1\n",
       "299        305          112                  3  3.0   3.5  8.65         0\n",
       "13         307          109                  3  4.0   3.0  8.00         1\n",
       "90         318          106                  2  4.0   4.0  7.92         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b5f3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_text_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edadcab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22      , 0.17857143, 0.25      , ..., 0.42857143, 0.25      ,\n",
       "        1.        ],\n",
       "       [0.88      , 0.96428571, 1.        , ..., 0.85714286, 0.91911765,\n",
       "        1.        ],\n",
       "       [0.3       , 0.71428571, 0.5       , ..., 0.57142857, 0.53308824,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.70220588,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.74632353,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.22058824,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9137be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fb2f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dheeraj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_dim=7))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))   #linear for regression always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2391ac17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82d71eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8c6df52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.7591 - val_loss: 0.6788\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5530 - val_loss: 0.4916\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3973 - val_loss: 0.3536\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2850 - val_loss: 0.2614\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2094 - val_loss: 0.1982\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1562 - val_loss: 0.1509\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1170 - val_loss: 0.1142\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0862 - val_loss: 0.0858\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0641 - val_loss: 0.0646\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0489 - val_loss: 0.0499\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0385 - val_loss: 0.0403\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0329 - val_loss: 0.0345\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0297 - val_loss: 0.0308\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0277 - val_loss: 0.0282\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0259 - val_loss: 0.0261\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0241 - val_loss: 0.0241\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0202 - val_loss: 0.0210\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0173 - val_loss: 0.0185\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0048 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train, epochs=100,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd5bedcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6922368 ],\n",
       "       [0.62203693],\n",
       "       [0.7996515 ],\n",
       "       [0.74401367],\n",
       "       [0.82775736],\n",
       "       [0.6469419 ],\n",
       "       [0.69291896],\n",
       "       [0.5381845 ],\n",
       "       [0.49429536],\n",
       "       [0.9279403 ],\n",
       "       [0.80689645],\n",
       "       [0.93417156],\n",
       "       [0.8828231 ],\n",
       "       [0.658539  ],\n",
       "       [0.7390228 ],\n",
       "       [0.7655298 ],\n",
       "       [0.80434084],\n",
       "       [0.87838197],\n",
       "       [0.53924245],\n",
       "       [0.7362926 ],\n",
       "       [0.5772737 ],\n",
       "       [0.796575  ],\n",
       "       [0.83856666],\n",
       "       [0.9130143 ],\n",
       "       [0.7087946 ],\n",
       "       [0.6174794 ],\n",
       "       [0.7097414 ],\n",
       "       [0.741515  ],\n",
       "       [0.88884544],\n",
       "       [0.64996225],\n",
       "       [0.9590151 ],\n",
       "       [0.60924035],\n",
       "       [0.78826255],\n",
       "       [0.78290856],\n",
       "       [0.70489013],\n",
       "       [0.6126811 ],\n",
       "       [0.51138824],\n",
       "       [0.7076106 ],\n",
       "       [0.9203563 ],\n",
       "       [0.8498749 ],\n",
       "       [0.81911826],\n",
       "       [0.63519806],\n",
       "       [0.86038333],\n",
       "       [0.66303843],\n",
       "       [0.9684982 ],\n",
       "       [0.7174957 ],\n",
       "       [0.7357795 ],\n",
       "       [0.81932974],\n",
       "       [0.6464396 ],\n",
       "       [0.68285275],\n",
       "       [0.79729974],\n",
       "       [0.5689757 ],\n",
       "       [0.7704741 ],\n",
       "       [0.78320676],\n",
       "       [0.72322446],\n",
       "       [0.89397895],\n",
       "       [0.4801033 ],\n",
       "       [0.47194576],\n",
       "       [0.7686175 ],\n",
       "       [0.78585935],\n",
       "       [0.8768287 ],\n",
       "       [0.7421987 ],\n",
       "       [0.88925487],\n",
       "       [0.6966201 ],\n",
       "       [0.5013798 ],\n",
       "       [0.80943763],\n",
       "       [0.8539897 ],\n",
       "       [0.7154705 ],\n",
       "       [0.6471753 ],\n",
       "       [0.7849767 ],\n",
       "       [0.7641559 ],\n",
       "       [0.4896502 ],\n",
       "       [0.6941676 ],\n",
       "       [0.59682477],\n",
       "       [0.81848097],\n",
       "       [0.41016805],\n",
       "       [0.6568534 ],\n",
       "       [0.62697095],\n",
       "       [0.6367881 ],\n",
       "       [0.6457338 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_text_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "173becbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26205647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-124319.80926933142"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6515c4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24846677d00>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
